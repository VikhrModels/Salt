base_model: "meta-llama/Llama-3.2-3B"
checkpoint_path: "results/Llama-3.2-3B_asr_speech_3_wav_1_tts_speech_5/checkpoint-4000"
save_dir: "./results"

data:
  - Vikhrmodels/librispeech_quantized
  - Vikhrmodels/parler_tts_with_description_quantized

text_data:
  - llm-blender/mix-instruct


start_audio_token: "<|start_of_audio|>"
end_audio_token: "<|end_of_audio|>"
end_sequence_token: "<|end_of_text|>"
n_special_tokens: 3

max_seq_length: 2048
raw_audio_length: 256000

path_to_cache: "/fsx/homes/Artem.Shelmanov@mbzuai.ac.ae/.cache"

allow_tf32: True

# Freezing settings
freeze_emb: False
freeze_ln: False
freeze_attn: False
freeze_ff: True
freeze_ff_layers:
  - 5
  - 6
  - 7
  - 8
  - 9
  - 12
  - 23
  - 14
  - 18
  - 19
  - 20
  - 0
  - 25

freeze_other: False

# Quantizer settings
quantizer:
  speech:
    n_new_tokens: 1024
  wav:
    n_new_tokens: 4096
  asr:
    - quantizer: speech
      n_codebooks: 3
    - quantizer: wav
      n_codebooks: 1

  tts:
    - quantizer: speech
      n_codebooks: 5

# Training settings
train_batch_size: 4
eval_batch_size: 1
learning_rate: 1e-5
gradient_accumulation_steps: 8
lr_scheduler_type: "cosine"
num_train_epochs: 10
num_warmup_steps: 10
checkpointing_steps: 2000
logging_steps: 20
weight_decay: 0.1
max_grad_norm: 0.25

# Logging settings
wandb_project_name: "vikhr4o-llama-tiny"
