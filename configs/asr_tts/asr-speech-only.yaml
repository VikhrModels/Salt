base_model: "Qwen/Qwen2.5-0.5B"
checkpoint_path: null
save_dir: "./results"

asr_data:
  - Vikhrmodels/librispeech_quantized
  - Vikhrmodels/parler_tts_with_description_quantized
  - Vikhrmodels/emilia_quantized-v1

tts_data: []

text_data: []


start_sequence_token: "<|im_start|>"
end_sequence_token: "<|im_end|>"
start_audio_token: "<|start_of_audio|>"
end_audio_token: "<|end_of_audio|>"

n_special_tokens: 3

max_seq_length: 4096
filter_long_audio: False

path_to_cache: null

allow_tf32: True

# Freezing settings
freeze:
    freeze_emb: False
    freeze_ln: False
    freeze_attn: False
    freeze_ff: False
    freeze_ff_layers:
      - 5
      - 6
      - 7
      - 8
      - 9
      - 12
      - 23
      - 14
      - 18
      - 19
      - 20
      - 0
      - 25

    freeze_other: False

tasks:
  - asr

# Quantizer settings
quantizer:
  speech:
    n_new_tokens: 1024
  wav:
    n_new_tokens: 0
  bigcodec:
    n_new_tokens: 0
  asr:
    - quantizer: speech
      n_codebooks: 1

  tts: []

# Training settings
train_batch_size: 3
eval_batch_size: 3
learning_rate: 1e-4
gradient_accumulation_steps: 1
lr_scheduler_type: "cosine"
num_train_epochs: 5
num_warmup_steps: 1000

weight_decay: 0.1
max_grad_norm: 0.25

torch_compile: False
save_total_limit: 3

# Logging settings
wandb_project_name: "asr-tts"
